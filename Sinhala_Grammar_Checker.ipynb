{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TOJARIh5tbk"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**install the necessary libraries**"
      ],
      "metadata": {
        "id": "_NonzPXE6Do7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "id": "LMsDlgFN59Sc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/MyDrive/grammar10.txt'\n",
        "with open(file_path, 'r', encoding='utf-16') as file:\n",
        "    data = [line.strip().split(\" \", 1) for line in file.readlines()]\n",
        "\n",
        "data_frame = pd.DataFrame(data, columns=[\"category\", \"text\"])\n",
        "data_frame[\"category\"] = data_frame[\"category\"].astype(int)\n",
        "data_frame['text'] = data_frame['text'].fillna('')\n",
        "\n",
        "text_data = data_frame['text']\n",
        "labels = data_frame['category']"
      ],
      "metadata": {
        "id": "3s9lhlTh6gLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_data, X_test_data, y_train_labels, y_test_labels = train_test_split(text_data, labels, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "v1VmX9AS6pbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer_instance = CountVectorizer(tokenizer=word_tokenize, token_pattern=None)\n",
        "X_train_vec = vectorizer_instance.fit_transform(X_train_data)\n",
        "X_test_vec = vectorizer_instance.transform(X_test_data)"
      ],
      "metadata": {
        "id": "zi4pjYXj7Cqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "classifier_model = SVC(kernel='linear', random_state=42)\n",
        "classifier_model.fit(X_train_vec, y_train_labels)"
      ],
      "metadata": {
        "id": "D6QlpzKlEPZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = classifier_model.predict(X_test_vec)\n",
        "model_accuracy = accuracy_score(y_test_labels, predictions)\n",
        "print(f\"Accuracy: {model_accuracy:.2f}\")"
      ],
      "metadata": {
        "id": "dfOXeHNy7buI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def grammar_check(input_text, vectorizer, model, dataframe):\n",
        "    \"\"\"\n",
        "    Check the grammar of a given input text and return the corrected text.\n",
        "    \"\"\"\n",
        "    sentences = nltk.sent_tokenize(input_text)\n",
        "    corrected_sentences = []\n",
        "    all_correct = True\n",
        "\n",
        "    for sentence in sentences:\n",
        "        vectorized_text = vectorizer.transform([sentence])\n",
        "        result = model.predict(vectorized_text)[0]\n",
        "\n",
        "        if result == 1:\n",
        "            corrected_sentences.append(sentence)  # Keep the original sentence if correct\n",
        "        else:\n",
        "            all_correct = False\n",
        "            correct_texts = dataframe[dataframe['category'] == 1]['text']\n",
        "            best_match = None\n",
        "            highest_similarity = 0\n",
        "\n",
        "            for correct_text in correct_texts:\n",
        "                input_set = set(sentence.split())\n",
        "                correct_set = set(correct_text.split())\n",
        "                similarity_score = len(input_set.intersection(correct_set)) / len(input_set.union(correct_set)) if input_set.union(correct_set) else 0\n",
        "                if similarity_score > highest_similarity:\n",
        "                    highest_similarity = similarity_score\n",
        "                    best_match = correct_text\n",
        "\n",
        "            if best_match:\n",
        "                corrected_sentences.append(best_match)\n",
        "            else:\n",
        "                corrected_sentences.append(sentence)\n",
        "\n",
        "    corrected_text = \" \".join(corrected_sentences)\n",
        "    return corrected_text, all_correct"
      ],
      "metadata": {
        "id": "TWvSvT9c7ikA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cross_val_scores = cross_val_score(classifier_model, X_train_vec, y_train_labels, cv=5, scoring='accuracy')\n",
        "print(f\"Cross-Validation Mean Accuracy: {cross_val_scores.mean():.2f}\")"
      ],
      "metadata": {
        "id": "koC1XWpy76BV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid_values = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [10, 20, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "grid_search_model = GridSearchCV(RandomForestClassifier(random_state=42), param_grid_values, cv=3, n_jobs=-1, verbose=2)\n",
        "grid_search_model.fit(X_train_vec, y_train_labels)\n",
        "best_classifier_model = grid_search_model.best_estimator_"
      ],
      "metadata": {
        "id": "tSQcSKOl8C8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf_matrix = confusion_matrix(y_test_labels, predictions)\n",
        "print(conf_matrix)\n",
        "print(classification_report(y_test_labels, predictions))"
      ],
      "metadata": {
        "id": "m6qxg-GX8K-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_new_sentence(input_sentence, vectorizer, model, dataframe):\n",
        "    corrected_sentence, all_correct = grammar_check(input_sentence, vectorizer, model, dataframe)\n",
        "\n",
        "    if all_correct:\n",
        "        print(\"The sentence is grammatically correct!\")\n",
        "    else:\n",
        "        print(\"The sentence has grammar issues. Corrected version:\")\n",
        "        print(corrected_sentence)\n",
        "\n",
        "new_sentence = \"මම බත් යමු\"\n",
        "test_new_sentence(new_sentence, vectorizer_instance, classifier_model, data_frame)\n"
      ],
      "metadata": {
        "id": "rn6Sq_JfNsNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "sentence_input = widgets.Textarea(\n",
        "    value='',\n",
        "    placeholder='Enter a Sinhala sentence for grammar check...',\n",
        "    description='Sentence:',\n",
        "    disabled=False,\n",
        "    layout=widgets.Layout(width='80%', height='150px')\n",
        ")\n",
        "\n",
        "output_area = widgets.Output()\n",
        "\n",
        "def on_button_click(b):\n",
        "    input_sentence = sentence_input.value\n",
        "    if input_sentence.strip():\n",
        "        corrected_sentence, all_correct = grammar_check(input_sentence, vectorizer_instance, classifier_model, data_frame)\n",
        "\n",
        "        with output_area:\n",
        "            output_area.clear_output()\n",
        "            if all_correct:\n",
        "                print(\"The sentence is grammatically correct!\")\n",
        "            else:\n",
        "                print(\"The sentence has grammar issues. Corrected version:\")\n",
        "                print(corrected_sentence)\n",
        "    else:\n",
        "        with output_area:\n",
        "            output_area.clear_output()\n",
        "            print(\"Please enter a sentence to check.\")\n",
        "\n",
        "\n",
        "check_button = widgets.Button(\n",
        "    description=\"Check Grammar\",\n",
        "    disabled=False,\n",
        "    button_style='success',\n",
        "    tooltip=\"Click to check grammar\"\n",
        ")\n",
        "\n",
        "check_button.on_click(on_button_click)\n",
        "display(sentence_input, check_button, output_area)\n"
      ],
      "metadata": {
        "id": "iW6GrBiWWpnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4xJ4i7Ncfke6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}